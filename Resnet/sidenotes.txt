fuse after ckpt has loaded

    # !!! google 'Batch normalization folding' if you found bn disappeared XD !!!

    # in fusion.py:

    #   fused_conv_w = conv_w * (bn_w * bn_var_rsqrt).reshape(shape)

    #   fused_conv_b = (conv_b - bn_rm) * bn_var_rsqrt * bn_w + bn_b

    # note self is Formal Parameter

# a good explaination of PTSQ : https://jermmy.github.io/2020/07/04/2020-7-4-post-training-quantization-2/

# noteï¼šx86å¹³å°ä¸Šè¦é˜²æ­¢vpmaddubswï¼ˆå‘é‡åŒ–8bitæ•´æ•°ä¹˜åŠ æŒ‡ä»¤ï¼‰æº¢å‡ºï¼Œå› æ­¤ä¸Šä¸€è¡Œçš„é»˜è®¤è®¾ç½®å…¶å®æ˜¯ 7 bitï¼ˆ0~127ï¼‰ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ˆåäº†ğŸ¤®ï¼‰
# è¿™ä¸ªä¼˜åŒ–å¯¹éx86å¹³å°æ— æ„ä¹‰
# ref1 implementation of pytorch observer https://github.com/pytorch/pytorch/blob/main/torch/ao/quantization/observer.py
# ref2 instruction doc https://en.wikichip.org/wiki/x86/avx512_vnni
