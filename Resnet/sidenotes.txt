fuse after ckpt has loaded

    # !!! google 'Batch normalization folding' if you found bn disappeared XD !!!

    # in fusion.py:

    #   fused_conv_w = conv_w * (bn_w * bn_var_rsqrt).reshape(shape)

    #   fused_conv_b = (conv_b - bn_rm) * bn_var_rsqrt * bn_w + bn_b

    # note self is Formal Parameter

# a good explaination of PTSQ : https://jermmy.github.io/2020/07/04/2020-7-4-post-training-quantization-2/

# note：x86平台上要防止vpmaddubsw（向量化8bit整数乘加指令）溢出，因此上一行的默认设置其实是 7 bit（0~127）！！！！！！！！！！（吐了🤮）
# 这个优化对非x86平台无意义
# ref1 implementation of pytorch observer https://github.com/pytorch/pytorch/blob/main/torch/ao/quantization/observer.py
# ref2 instruction doc https://en.wikichip.org/wiki/x86/avx512_vnni
